@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{dataset,
 author = {F. Huerta and R. Huerta and T. Mosqueiro and J. Fonollosa and N. Rulkov and I. Rodriguez-Lujan},
 Title  = {"Gas sensors for home activity monitoring Data Set"},
 note   = {\url{https://archive.ics.uci.edu/ml/datasets/Gas+sensors+for+home+activity+monitoring}, Accedida 10/12/2021},
 year = {2016},
 month = {Jul.},
}

@misc{visualizacion_series,
 author = {R. Huerta and T. Mosqueiro and J. Fonollosa and N. Rulkov and I. Rodriguez-Lujan},
 Title  = {"Online decorrelation of humidity and temperature in chemical sensors for continuous monitoring"},
 note   = {\url{https://github.com/thmosqueiro/ENose-Decorr_Humdt_Temp}, Accedida 10/12/2021},
 year = {2016},
 month = {Jul.},
}

@misc{multiprocessing,
 Title  = "Python Multiprocessing Library",
 author = "Python Software Foundation",
 note   = {\url{https://docs.python.org/3/library/multiprocessing.html}},
}

@Article{matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@misc{pandas,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    note   = {\url{https://doi.org/10.5281/zenodo.3509134}},
}

@Article{numpy,
 title         = {Array programming with {NumPy}},
 author        = {Harris, C.R. and  Millman, K.J. and van der Walt, S.J. et al},
 year          = {2020},
 month         = Sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {\url{https://doi.org/10.1038/s41586-020-2649-2}}
}


@Article{Confusion_Matrix,
 title         = {Glossary of Terms},
 author        = {Kohavi, R. and Provost, F.},
 year          = {1998},
 month         = Feb,
 journal       = {Machine Learning},
 volume        = {30},
 pages         = {271–274},
 doi           = {10.1023/A:1017181826899},
 publisher     = {Kluwer Academic Publishers},
 url           = {\url{https://doi.org/10.1023/A:1017181826899}}
}

@article{naive_bayes,
author = {Hand, David and Yu, Keming},
year = {2007},
month = {05},
pages = {385 - 398},
title = {Idiot's Bayes: Not So Stupid after All?},
volume = {69},
journal = {International Statistical Review},
doi = {10.1111/j.1751-5823.2001.tb00465.x}
}

@article{knn,
  title     = "An algorithm for a selective nearest neighbor decision rule
               (Corresp.)",
  author    = "Ritter, G and Woodruff, H and Lowry, S and Isenhour, T",
  journal   = "IEEE Trans. Inf. Theory",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  21,
  number    =  6,
  pages     = "665--669",
  month     =  nov,
  year      =  1975,
  copyright = "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
  language  = "en"
}

@article{LogisticRegression,
author = {Alves, Antônio and Fernandes, Antônio and Britto, Dalson and Figueiredo, Dalson and Rocha, Enivaldo and Da, Willber and Nascimento, Silva},
year = {2020},
month = {12},
pages = {1},
title = {Read this paper if you want to learn logistic regression},
volume = {28},
journal = {Revista de Sociologia e Política},
doi = {10.1590/1678-987320287406en}
}


@article{neuralnetwork,
author = {Zhang, Peter},
year = {2000},
month = {12},
pages = {451 - 462},
title = {Neural Networks for Classification: A Survey},
volume = {30},
journal = {Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on},
doi = {10.1109/5326.897072}
}

﻿@Article{randomforests,
author={Breiman, Leo},
title={Random Forests},
journal={Machine Learning},
year={2001},
month={Oct},
day={01},
volume={45},
number={1},
pages={5-32},
abstract={Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
issn={1573-0565},
doi={10.1023/A:1010933404324},
url={https://doi.org/10.1023/A:1010933404324}
}

